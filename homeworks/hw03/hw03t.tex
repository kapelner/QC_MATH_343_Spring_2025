\documentclass[12pt]{article}

\include{preamble}

\newtoggle{professormode}
\toggletrue{professormode} %STUDENTS: DELETE or COMMENT this line



\title{MATH 343 / 643 Homework \#3}

\author{Professor Adam Kapelner} %STUDENTS: write your name here

\iftoggle{professormode}{
\date{Due 11:59PM May 18, \the\year \\ \vspace{0.5cm} \small (this document last updated \currenttime~on \today)}
}

\renewcommand{\abstractname}{Instructions and Philosophy}

\begin{document}
\maketitle

\iftoggle{professormode}{
\begin{abstract}
The path to success in this class is to do many problems. Unlike other courses, exclusively doing reading(s) will not help. Coming to lecture is akin to watching workout videos; thinking about and solving problems on your own is the actual ``working out.''  Feel free to \qu{work out} with others; \textbf{I want you to work on this in groups.}

Reading is still \textit{required}. For this homework set, read as much as you can online about the topics we covered.

The problems below are color coded: \ingreen{green} problems are considered \textit{easy} and marked \qu{[easy]}; \inorange{yellow} problems are considered \textit{intermediate} and marked \qu{[harder]}, \inred{red} problems are considered \textit{difficult} and marked \qu{[difficult]} and \inpurple{purple} problems are extra credit. The \textit{easy} problems are intended to be ``giveaways'' if you went to class. Do as much as you can of the others; I expect you to at least attempt the \textit{difficult} problems. 

This homework is worth 100 points but the point distribution will not be determined until after the due date. See syllabus for the policy on late homework.

Up to 7 points are given as a bonus if the homework is typed using \LaTeX. Links to instaling \LaTeX~and program for compiling \LaTeX~is found on the syllabus. You are encouraged to use \url{overleaf.com}. If you are handing in homework this way, read the comments in the code; there are two lines to comment out and you should replace my name with yours and write your section. The easiest way to use overleaf is to copy the raw text from hwxx.tex and preamble.tex into two new overleaf tex files with the same name. If you are asked to make drawings, you can take a picture of your handwritten drawing and insert them as figures or leave space using the \qu{$\backslash$vspace} command and draw them in after printing or attach them stapled.

The document is available with spaces for you to write your answers. If not using \LaTeX, print this document and write in your answers. I do not accept homeworks which are \textit{not} on this printout. Keep this first page printed for your records.

\end{abstract}

\thispagestyle{empty}
\vspace{1cm}
NAME: \line(1,0){380}
\clearpage
}

\problem{Consider the Poisson linear regression model with one feature, time:

\beqn
Y_1, Y_2, \ldots, Y_n ~|~ t_1, t_2, \ldots, t_n \inddist \poisson{e^{\beta_0 + \beta_1 t_i}}
\eeqn

\noindent and consider a Bayesian approach to inference.}

\begin{enumerate}

\easysubproblem{What is the parameter space for the two parameters of interest?}\spc{1}

\easysubproblem{Assume a flat prior $f(\beta_0, \beta_1) \propto 1$. Find the kernel of the posterior distribution $f(\beta_0, \beta_1\,|\,y_1, \ldots, y_n, t_1, \ldots, t_n)$.}\spc{3}

\easysubproblem{Find the log of the kernel of the posterior distribution.}\spc{2}


\easysubproblem{Find the kernel of the conditional distribution $f(\beta_0\,|\,y_1, \ldots, y_n, t_1, \ldots, t_n, \beta_1)$. Is it a brand name rv?}\spc{3}

\easysubproblem{Find the kernel of the conditional distribution $f(\beta_1\,|\,y_1, \ldots, y_n, t_1, \ldots, t_n, \beta_0)$. Is it a brand name rv?}\spc{4}

\intermediatesubproblem{[MA, not covered on the final] Given your answer in (a), the $\support{\beta_0}$, provide a proposal distribution  for the conditional distribution of $\beta_0$:

\beqn
q(\beta_0^*\,|\,\beta_{0_{t-1}}, y_1, \ldots, y_n, t_1, \ldots, t_n, \beta_1, \phi)= \hspace{6in}
\eeqn}

\intermediatesubproblem{[MA, not covered on the final] Given your answer in (a), the $\support{\beta_1}$, provide a proposal distribution  for the conditional distribution of $\beta_1$:

\beqn
q(\beta_1^*\,|\,\beta_{1_{t-1}}y_1, \ldots, y_n, t_1, \ldots, t_n, \beta_0, \phi)= \hspace{6in}
\eeqn}

\end{enumerate}


\problem{This question is about basic causality, structural equation models and their visual representation as directed acyclic graphs (DAGs).}

\begin{enumerate}

\easysubproblem{We run a OLS to fit $\hat{y} = b_0 + b_1 x$ and find there is a statistically significant rejection of $H_0: \beta_1 = 0$. If this test was decided correctly, what do we call the relationship between $x$ and $y$? (The answer is one word).}\spc{0}

\easysubproblem{If this test was decided incorrectly, what do we call the relationship between $x$ and $y$? (The answer is two words).}\spc{0}

\easysubproblem{Draw an example DAG where $x$ causes $y$.}\spc{0.5}

\easysubproblem{Draw an example DAG where $x$ is correlated to $y$ but is not causal.}\spc{2}

\easysubproblem{Draw an example DAG that can result in a spurious correlation of $x$ and $y$.}\spc{1}

\easysubproblem{Draw an example DAG where $x$ causes $y$ but its effect is fully blocked by $z$.}\spc{0.5}

\easysubproblem{Draw an example DAG where $x$ causes $y$ but its effect is partially blocked by $z$.}\spc{2}

\easysubproblem{Draw an example DAG that results in a Berkson's paradox between $x$ and $y_1$. Denote the collider variable as $y_2$.}\spc{1}


\easysubproblem{Draw an example DAG that results in a Simpson's paradox between $x$ and $y$. Denote the confounding variable as $u$.}\spc{2}


\easysubproblem{In the previous Simpson's paradox DAG, provide an example structural equation for $y$ and provide an example structural equation for $x$.}\spc{2}

\easysubproblem{Consider observed covariates $x_1, x_2, x_3$ and phenomenon $y$. Draw a realistic DAG for this setting.}\spc{7}



\end{enumerate}


\problem{This question is about causal and correlational interpretations for generalized linear models.}

\begin{enumerate}

\easysubproblem{We run the following model on the \texttt{diamonds} dataset where $y$ is the price of the diamond}

\begin{verbatim}
> summary(lm(price ~ ., diamonds))

              Estimate Std. Error t value Pr(>|t|)    
(Intercept)   2184.477    408.197   5.352 8.76e-08 ***
carat        11256.978     48.628 231.494  < 2e-16 ***
cutGood        579.751     33.592  17.259  < 2e-16 ***
cutVery Good   726.783     32.241  22.542  < 2e-16 ***
cutPremium     762.144     32.228  23.649  < 2e-16 ***
cutIdeal       832.912     33.407  24.932  < 2e-16 ***
colorE        -209.118     17.893 -11.687  < 2e-16 ***
colorF        -272.854     18.093 -15.081  < 2e-16 ***
colorG        -482.039     17.716 -27.209  < 2e-16 ***
colorH        -980.267     18.836 -52.043  < 2e-16 ***
colorI       -1466.244     21.162 -69.286  < 2e-16 ***
colorJ       -2369.398     26.131 -90.674  < 2e-16 ***
claritySI2    2702.586     43.818  61.677  < 2e-16 ***
claritySI1    3665.472     43.634  84.005  < 2e-16 ***
clarityVS2    4267.224     43.853  97.306  < 2e-16 ***
clarityVS1    4578.398     44.546 102.779  < 2e-16 ***
clarityVVS2   4950.814     45.855 107.967  < 2e-16 ***
clarityVVS1   5007.759     47.160 106.187  < 2e-16 ***
clarityIF     5345.102     51.024 104.757  < 2e-16 ***
depth          -63.806      4.535 -14.071  < 2e-16 ***
table          -26.474      2.912  -9.092  < 2e-16 ***
x            -1008.261     32.898 -30.648  < 2e-16 ***
y                9.609     19.333   0.497    0.619    
z              -50.119     33.486  -1.497    0.134    
\end{verbatim}

What is the interpretation of the $b$ for \texttt{carat} (the unit of this feature is \qu{carats})?\spc{5}

\hardsubproblem{What is the interpretation of the $b$ for \texttt{cutIdeal} (note: the reference category for \texttt{cut} is \texttt{Fair})?}\spc{6}

\easysubproblem{We run the following model on the \texttt{Pima.tr2} dataset where $y$ is 1 if the subject had diabetes or 0 if not.}

\vspace{-0.2cm}
\begin{verbatim}
> summary(glm(type ~ ., MASS::Pima.tr2, family = "binomial"))

             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -9.773062   1.770386  -5.520 3.38e-08 ***
npreg        0.103183   0.064694   1.595  0.11073    
glu          0.032117   0.006787   4.732 2.22e-06 ***
bp          -0.004768   0.018541  -0.257  0.79707    
skin        -0.001917   0.022500  -0.085  0.93211    
bmi          0.083624   0.042827   1.953  0.05087 .  
ped          1.820410   0.665514   2.735  0.00623 ** 
age          0.041184   0.022091   1.864  0.06228 .  
\end{verbatim}

What is the interpretation of the $b$ for \texttt{age} (the unit of this feature is age)?\spc{6}

\easysubproblem{What is the interpretation of the $b$ for \texttt{glu} (the unit of this feature is mg/dL) if \texttt{glu} is known to be causal?}\spc{6}

\easysubproblem{We run the following model on the \texttt{phillippines} household dataset where $y$ is the number of people living in a household.}

\vspace{-0.2cm}
\begin{verbatim}
> summary(MASS::glm.nb(total ~ ., read.csv("philippines_housing.csv")))

                                   Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        1.447108   0.088204  16.406  < 2e-16 ***
locationDavaoRegion               -0.011108   0.064367  -0.173  0.86298    
locationIlocosRegion               0.053589   0.063284   0.847  0.39711    
locationMetroManila                0.074016   0.056731   1.305  0.19201    
locationVisayas                    0.131151   0.050440   2.600  0.00932 ** 
age                               -0.004896   0.001136  -4.309 1.64e-05 ***
roofPredominantly Strong Material  0.043376   0.052705   0.823  0.41051   
\end{verbatim}

What is the interpretation of the $b$ for \texttt{age} (the unit of this feature is years)?\spc{7}


\easysubproblem{We run the following Weibull regression model on the \texttt{lung} dataset where $y$ is survival of the patient.}

\vspace{-0.2cm}
\begin{verbatim}
> lung = na.omit(survival::lung)
> lung$status = lung$status - 1 #needs to be 0=alive, 1=dead
> summary(survreg(Surv(lung$time, lung$status) ~ 
      inst + sex + ph.ecog + ph.karno + wt.loss, lung))

               Value Std. Error     z       p
(Intercept)  7.13673    0.74732  9.55 < 2e-16
inst         0.02042    0.00877  2.33  0.0199
sex          0.39717    0.13852  2.87  0.0041
ph.ecog     -0.69588    0.15463 -4.50 6.8e-06
ph.karno    -0.01558    0.00749 -2.08  0.0376
wt.loss      0.00977    0.00525  1.86  0.0626
Log(scale)  -0.36704    0.07272 -5.05 4.5e-07
\end{verbatim}

What is the interpretation of the $b$ for \texttt{wt.loss} (the unit of this feature is lbs) if \texttt{wt.loss} is known to be causal?\spc{6}


\easysubproblem{What is the interpretation of the $b$ for \texttt{ph.ecog} (the unit of this feature is mg/dL) if \texttt{ph.ecog} is known to be causal?}\spc{6}

\end{enumerate}



\problem{This problem is about controlling values of variables to allow for causal inference.}

\begin{enumerate}

\easysubproblem{Redraw the \qu{master decision tree} of what to do in every situation beginning with the root node of \qu{Can we assume a DAG?}}\spc{20}

\easysubproblem{Explain why controlling / manipulating the values of $x$ allows for causal inference of $x$ on $y$.}\spc{3}

\intermediatesubproblem{Explain why a typical observational study (i.e. just collecting data and assembling it into $\mathbb{D}$) cannot allow for causal inference of $x$ on $y$.}\spc{3}

\easysubproblem{Give an example case (different from the one we spoke about in class) where controlling / manipulating the values of $x$ is impossible.}\spc{2.5}

\easysubproblem{Give an example case (different from the one we spoke about in class) where controlling / manipulating the values of $x$ is unethical.}\spc{2.5}

\easysubproblem{Give an example case (different from the one we spoke about in class) where controlling / manipulating the values of $x$ is impractical / unaffordable.}\spc{2.5}


\hardsubproblem{Assume in the \texttt{diamonds} dataset that the variable \texttt{cut} was manipulated by the experimenter prior to assessing the price $y$. This isn't absurd since raw diamonds can be cut differently but their color and clarity cannot be altered. Using the linear regression output from the previous problem, what is the interpretation of the $b$ for \texttt{cutIdeal}. The reference category for this variable is \texttt{Fair}.}\spc{6}

\end{enumerate}


\problem{This problem is about randomized controlled trials (RCTs). Let  $n$ denote the number of subjects, let $\w$ denote the variable of interest which you seek causal inference for its effect. Here we assume $\w$ is a binary allocation / assignment vector of the specific manipulation $w_i$ for each subject (thus the experiment has \qu{two arms} which is sometimes called a \qu{treatment-control experiment} or \qu{pill-placebo trial} or an \qu{AB test}. Let $\y$ denote the measurements of the phenomenon of interest for each subject and let $\x_{\cdot 1}, \ldots, \x_{\cdot p}$ denote the $p$ baseline covariate measurements for each subject.}

\begin{enumerate}

\easysubproblem{How many possible allocations are there in this experiment?}\spc{-0.5}

\easysubproblem{What are the three advantages of randomizing $\w$? We spoke about two main advantages and one minor advantage.}\spc{6}

\easysubproblem{In Fisher's Randomization test, what is the null hypothesis? Explain what this really means.}\spc{4}

\easysubproblem{Explain step-by-step how to run Fisher's Randomization test.}\spc{5}

Assume now that Let $\Y = \beta_0 \onevec_n + \beta_T \w + \berrorrv$ where $\errorrv_1, \ldots, \errorrv_n \iid$ mean zero and has homoskedastic variance $\sigsq$.

\easysubproblem{What this the parameter of interest in causal inference? What is its name?}\spc{2}

\easysubproblem{Assume we employ OLS to estimate $\beta_T$. We proved previously that OLS estimators are unbiased for any error distribution with mean zero. Find the $\mse{B_T}$.}\spc{6}

\easysubproblem{Prove that the optimal $\w$ has equal allocation to each arm.}\spc{4}

\easysubproblem{Explain how to run an experiment using the \textit{completely randomized design}.}\spc{2}

Assume now that Let $\Y = \beta_0 \onevec_n + \beta_T \w + \beta_1 \x_{\cdot 1} + \ldots + \beta_p \x_{\cdot p} + \berrorrv$ where $\errorrv_1, \ldots, \errorrv_n \iid$ mean zero and have homoskedastic variance $\sigsq$.

\hardsubproblem{Prove that $B_T$ is unbiased over the distribution of $\berrorrv$ and $\W$.}\spc{6}

\easysubproblem{What is the purpose using a \textit{restricted design}? That is, using a set of allocations that is a subset of the full set of the completely randomized design.}\spc{5}

\intermediatesubproblem{Explain how to run an experiment using Fisher's \textit{blocking design} where you block on $\x_{\cdot 1}$, a factor with three levels and $\x_{\cdot 2}$, a factor with two levels.}\spc{7}


\easysubproblem{What are the two main disadvantages to using Fisher's \textit{blocking design}?}\spc{3}

\easysubproblem{Explain how to run an experiment using Student's \textit{rerandomization design} where you let the imbalance metric be 

\beqn
\sum_{j=1}^p \frac{\abss{\xbar_{j_T} - \xbar_{j_C}}}{s^2_{x_{j_T}} / (n/2) + s^2_{x_{j_C}} / (n/2)}
\eeqn}~\spc{5.5}

\easysubproblem{Explain how to run an experiment using the \textit{pairwise matching design}.}\spc{6}

\easysubproblem{Does the pairwise matching design provide better imbalance on the observed covariates than the rerandomization design? Y/N}\spc{0}

\end{enumerate}


\problem{This question is about hazard rates and Cox proportion hazard models. This will only be required if we have the two lectures on these models.}


\begin{enumerate}

\easysubproblem{What is the definition of the hazard rate $h(t)$?}\spc{0}

\easysubproblem{If $X \sim \stduniform$, derive the hazard rate $h(t)$.}\spc{2}

\easysubproblem{Give an example of a real-world phenomenon $T$ whose $h(t)$ is a bathtub shape.}\spc{1}

\easysubproblem{Prove that $S(t) = e^{-\displaystyle\int_0^t h(u) du}$.}\spc{6}

\hardsubproblem{Explain why the assumption that $h(t) = h_0(t)e^{\beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_p x_p}$ is called the \qu{proportional hazard model}.}\spc{4}

\easysubproblem{Under the proportional hazard model, find the likelihood $\mathcal{L}(\bbeta, h_0; \X, \y)$.}\spc{4}

\easysubproblem{Now let $h_i := h_0(y_i)$ and $H_i := \int_0^{y_i} h_0(u)du$. Find $\mathcal{L}(\bbeta, h_1, \ldots, h_n, H_1, \ldots, H_n; \X, \y)$.}\spc{4}


\easysubproblem{Now assume (1) all $y_i$'s are uniquely-valued and (2) $H_i \approx h_1 + \ldots + h_i$ and find $\doublehat{h}_i^{MLE}$.}\spc{4}

\easysubproblem{[MA] Find $\doublehat{\bbeta}^{MLE}$.}\spc{7}

\intermediatesubproblem{We now run the following Cox proportional hazard model on the \texttt{lung} dataset where $y$ is survival of the patient.}

\vspace{-0.2cm}
\begin{verbatim}
> mod = coxph(surv_obj ~ inst + sex + ph.ecog + ph.karno + wt.loss, lung)
> summary(mod)

              coef exp(coef)  se(coef)      z Pr(>|z|)    
inst     -0.030042  0.970404  0.012931 -2.323  0.02016 *  
sex      -0.571959  0.564419  0.198865 -2.876  0.00403 ** 
ph.ecog   0.993224  2.699926  0.232115  4.279 1.88e-05 ***
ph.karno  0.021492  1.021725  0.011222  1.915  0.05547 .  
wt.loss  -0.014800  0.985309  0.007664 -1.931  0.05348 .  
\end{verbatim}

What is the interpretation of the $b$ for \texttt{wt.loss} (the unit of this feature is lbs)?\spc{3}

\end{enumerate}

\end{document}

